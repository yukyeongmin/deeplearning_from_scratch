{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.3919 - accuracy: 0.8580 - val_loss: 0.2850 - val_accuracy: 0.8960\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.2500 - accuracy: 0.9076 - val_loss: 0.2532 - val_accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.2084 - accuracy: 0.9228 - val_loss: 0.2664 - val_accuracy: 0.9044\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1746 - accuracy: 0.9344 - val_loss: 0.2511 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1451 - accuracy: 0.9463 - val_loss: 0.2401 - val_accuracy: 0.9146\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1187 - accuracy: 0.9560 - val_loss: 0.2376 - val_accuracy: 0.9214\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0976 - accuracy: 0.9638 - val_loss: 0.2718 - val_accuracy: 0.9168\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0809 - accuracy: 0.9694 - val_loss: 0.3065 - val_accuracy: 0.9222\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0655 - accuracy: 0.9755 - val_loss: 0.3523 - val_accuracy: 0.9182\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0562 - accuracy: 0.9785 - val_loss: 0.3658 - val_accuracy: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f56610c40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.naver.com/jeonghj66/222005972393 의 코드를 가져옴\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#하이퍼파라미터 정의\n",
    "EPOCHS = 10\n",
    "\n",
    "#네트워크 구조 정의\n",
    "def MyModel():\n",
    "    return Sequential([Conv2D(32, (3, 3), padding='same', activation='relu'), # 28x28x32, same=zero-padding | valid=no-padding\n",
    "                       MaxPool2D(), # 14x14x32, 디폴트가 2 stripe로 크기를 절반으로 줄여준다\n",
    "                       Conv2D(64, (3, 3), padding='same', activation='relu'), # 14x14x64\n",
    "                       MaxPool2D(), # 7x7x64\n",
    "                       Conv2D(128, (3, 3), padding='same', activation='relu'), # 7x7x128\n",
    "                       Flatten(), # 7x7x128 = 6272\n",
    "                       Dense(128, activation='relu'), # 6272 -> 128\n",
    "                       Dense(10, activation='softmax')]) # 128 -> 10\n",
    "\n",
    "#데이터 불러오기\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# NHWC : 배치 + Height + Width + Channel\n",
    "x_train = x_train[..., np.newaxis] # 위의 4번째 채널을 추가\n",
    "x_test = x_test[..., np.newaxis] # 위의 4번째 채널을 추가\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)\n",
    "\n",
    "#모델 생성\n",
    "model = MyModel()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#모델 학습\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs231n lecture8 deep learning software 참고\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# tf v1의 문법사용을 위해\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "N, D, H = 64, 1000, 100\n",
    "# placeholder - 변수를 선언 but 초기값 설정은 나중에 하겠다.\n",
    "x = tf.placeholder(tf.float32, shape=(N,D))\n",
    "y = tf.placeholder(tf.float32, shape=(N,D))\n",
    "w1 = tf.placeholder(tf.random_normal, shape=(D,H))\n",
    "w2 = tf.placeholder(tf.random_normal, shape=(H,D))\n",
    "\n",
    "# dot product 후 Relu 활성화 함수처리 결과\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff**2, axis=1))\n",
    "\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "\n",
    "# 모델링 설계후 tf.Sesson()으로 확정 필요\n",
    "with tf.Session() as sess:\n",
    "    values = {x: np.random.randn(N, D),\n",
    "             w1: np.random.randn(D, H),\n",
    "             w2: np.random.randn(H, D),\n",
    "             y: np.random.randn(N, D),}\n",
    "    \n",
    "    # training\n",
    "    learning_rate = 1e-5\n",
    "    for t in range(50):\n",
    "        # 오차 역전파\n",
    "        out = sess.run([loss, grad_w1, grad_w2], feed_dict=values)\n",
    "        loss_val, grad_w1_val, grad_w2_val = out\n",
    "        values[w1] -= learning_rate * grad_w1_val\n",
    "        values[w2] -= learning_rate * grad_w2_val\n",
    "\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs231n lecture8 deep learning software 참고\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# tf v1의 문법사용을 위해\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "N, D, H = 64, 1000, 100\n",
    "# placeholder - 변수를 선언 but 초기값 설정은 나중에 하겠다.\n",
    "x = tf.placeholder(tf.float32, shape=(N,D))\n",
    "y = tf.placeholder(tf.float32, shape=(N,D))\n",
    "w1 = tf.Variable(tf.random_normal((D,H))) # 정규분포\n",
    "w2 = tf.Variable(tf.random_normal((H,D)))\n",
    "\n",
    "# dot product 후 Relu 활성화 함수처리 결과\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff**2, axis=1))\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "\n",
    "learning_rate = 1e-5\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "update = tf.group(new_w1, new_w2) # 이문장이 빠지면 학습이 이루어 지지 않음\n",
    "\n",
    "# 모델링 설계후 tf.Sesson()으로 확정 필요\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x: np.random.randn(N, D),\n",
    "             y: np.random.randn(N, D),}\n",
    "    losses = []\n",
    "    \n",
    "    # training\n",
    "    for t in range(50):\n",
    "        loss_val,_ = sess.run([loss, update], feed_dict = values)\n",
    "\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d1e4fbd8fa9b>:12: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\fibik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dense() got an unexpected keyword argument 'intputx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d1e4fbd8fa9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintputx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkerner_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: dense() got an unexpected keyword argument 'intputx'"
     ]
    }
   ],
   "source": [
    "# cs231n lecture8 deep learning software 참고\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# tf v1의 문법사용을 위해\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "N, D, H = 64, 1000, 100\n",
    "init = tf.contrib.layers.xavier_initializer() # tf v2가 나오면서 삭제된 함수\n",
    "h = tf.layers.dense(inputs = x, units =H, activation=tf.nn.relu, kernel_initializer = init)\n",
    "y_pred = tf.layers.dense(intputx = h, units=D, kerner_initializer=init)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e0)\n",
    "updates = optimizer.minimize(loss)\n",
    "\n",
    "# 모델링 설계후 tf.Sesson()으로 확정 필요\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    values = {x: np.random.randn(N, D),\n",
    "             y: np.random.randn(N, D),}\n",
    "    losses = []\n",
    "    \n",
    "    # training\n",
    "    for t in range(50):\n",
    "        loss_val,_ = sess.run([loss, update], feed_dict = values)\n",
    "\n",
    "        print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ead02b13cfd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 완전 연결\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                   \u001b[1;31m# 활성화 함수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "# cs231n lecture 8 강의 참고\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "N, D, H = 64, 1000, 100\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim = D, output_dim = H)) # 완전 연결\n",
    "model.add(Activation('relu'))                   # 활성화 함수\n",
    "model.add(Dense(input_dim=H, output_dim = D))\n",
    "\n",
    "optimizer = SGD(lr = 1e0)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "x = np.random.randn(N, D)\n",
    "y = np.random.randn(N, D)\n",
    "history = model.fit(x, y, nb_epoch=50, batch_size=N, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
