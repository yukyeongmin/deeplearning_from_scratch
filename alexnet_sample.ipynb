{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.3825 - accuracy: 0.8609 - val_loss: 0.2889 - val_accuracy: 0.8930\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.2426 - accuracy: 0.9108 - val_loss: 0.2516 - val_accuracy: 0.9078\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.1998 - accuracy: 0.9262 - val_loss: 0.2370 - val_accuracy: 0.9132\n",
      "Epoch 4/10\n",
      " 171/1875 [=>............................] - ETA: 52s - loss: 0.1673 - accuracy: 0.9364"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#하이퍼파라미터 정의\n",
    "EPOCHS = 10\n",
    "\n",
    "#네트워크 구조 정의\n",
    "def MyModel():\n",
    "    return Sequential([Conv2D(32, (3, 3), padding='same', activation='relu'), # 28x28x32, same=zero-padding | valid=no-padding\n",
    "                       MaxPool2D(), # 14x14x32, 디폴트가 2 stripe로 크기를 절반으로 줄여준다\n",
    "                       Conv2D(64, (3, 3), padding='same', activation='relu'), # 14x14x64\n",
    "                       MaxPool2D(), # 7x7x64\n",
    "                       Conv2D(128, (3, 3), padding='same', activation='relu'), # 7x7x128\n",
    "                       Flatten(), # 7x7x128 = 6272\n",
    "                       Dense(128, activation='relu'), # 6272 -> 128\n",
    "                       Dense(10, activation='softmax')]) # 128 -> 10\n",
    "\n",
    "#데이터 불러오기\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# NHWC : 배치 + Height + Width + Channel\n",
    "x_train = x_train[..., np.newaxis] # 위의 4번째 채널을 추가\n",
    "x_test = x_test[..., np.newaxis] # 위의 4번째 채널을 추가\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)\n",
    "\n",
    "#모델 생성\n",
    "model = MyModel()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#모델 학습\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
